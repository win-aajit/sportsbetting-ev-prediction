{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e3c73fa-9b4a-4fec-906a-fb0e7e3b57f9",
   "metadata": {},
   "source": [
    "# Sports Betting EV Prediction Project\n",
    "\n",
    "In this project, we analyze historical English Premier League data, build predictive models for match outcomes, calculate expected value (EV) for betting opportunities, and simulate potential profits using backtesting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d109f01-df82-4bb0-9ab6-daf6afe558c9",
   "metadata": {},
   "source": [
    "### Data Loading and Cleaning\n",
    "\n",
    "We start by loading English Premier League (EPL) historical match data from Football-Data.org. We select key columns like home/away teams, match results, and bookmaker odds, and compute normalized implied probabilities to adjust for bookmaker overround.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b39c7e1-9048-446e-9392-fdbbf51ca376",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV you provided\n",
    "df = pd.read_csv('E0.csv')\n",
    "\n",
    "# Preview the data\n",
    "print(df.head())\n",
    "\n",
    "# Select key columns\n",
    "df = df[['Date', 'HomeTeam', 'AwayTeam', 'FTR', 'B365H', 'B365D', 'B365A']]\n",
    "\n",
    "# Rename columns for easier handling\n",
    "df = df.rename(columns={\n",
    "    'B365H': 'Home_Odds',\n",
    "    'B365D': 'Draw_Odds',\n",
    "    'B365A': 'Away_Odds',\n",
    "    'FTR': 'Result'\n",
    "})\n",
    "\n",
    "# Convert 'Date' to datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'], dayfirst=True, errors='coerce')\n",
    "\n",
    "# Drop rows with missing odds\n",
    "df = df.dropna(subset=['Home_Odds', 'Draw_Odds', 'Away_Odds'])\n",
    "\n",
    "# Compute implied probabilities (1/odds)\n",
    "df['Imp_Prob_Home'] = 1 / df['Home_Odds']\n",
    "df['Imp_Prob_Draw'] = 1 / df['Draw_Odds']\n",
    "df['Imp_Prob_Away'] = 1 / df['Away_Odds']\n",
    "\n",
    "# Normalize probabilities (bookmaker overround adjustment)\n",
    "df['Total_Imp_Prob'] = df['Imp_Prob_Home'] + df['Imp_Prob_Draw'] + df['Imp_Prob_Away']\n",
    "df['Norm_Prob_Home'] = df['Imp_Prob_Home'] / df['Total_Imp_Prob']\n",
    "df['Norm_Prob_Draw'] = df['Imp_Prob_Draw'] / df['Total_Imp_Prob']\n",
    "df['Norm_Prob_Away'] = df['Imp_Prob_Away'] / df['Total_Imp_Prob']\n",
    "\n",
    "# Encode result: H → 0, D → 1, A → 2\n",
    "result_map = {'H': 0, 'D': 1, 'A': 2}\n",
    "df['Result_Code'] = df['Result'].map(result_map)\n",
    "\n",
    "# Final preview\n",
    "print(df.head())\n",
    "\n",
    "# Save cleaned data if needed\n",
    "df.to_csv('cleaned_epl_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0edfea6-63fd-495a-bb70-99a0171672e0",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis (EDA)\n",
    "\n",
    "Before modeling, we explore the data to understand its basic characteristics. We review the distribution of match outcomes (home win, draw, away win) and summarize the odds data to identify any class imbalances or unexpected patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b15d4d-7fed-4e81-bbc6-1a35d411bdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Match outcome counts:\")\n",
    "print(df['Result'].value_counts())\n",
    "\n",
    "print(\"\\nOdds summary stats:\")\n",
    "print(df[['Home_Odds', 'Draw_Odds', 'Away_Odds']].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc528f41-5b42-4f7f-b5f7-c1a35c0cdbf2",
   "metadata": {},
   "source": [
    "### Model Training and Evaluation\n",
    "\n",
    "We primarily train a balanced logistic regression model (with class weighting) and a random forest classifier to predict match outcomes. To provide a meaningful comparison, we also include an unbalanced logistic regression model as a retrospective baseline. We evaluate all models using accuracy, precision, recall, and f1-scores to determine which performs best and informs our downstream expected value (EV) calculations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fa5be2-3a38-4264-8608-eab7db0c80c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Features: normalized bookmaker probabilities\n",
    "features = df[['Norm_Prob_Home', 'Norm_Prob_Draw', 'Norm_Prob_Away']]\n",
    "target = df['Result_Code']\n",
    "\n",
    "# Split data (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression with class balancing\n",
    "logreg_balanced = LogisticRegression(solver='lbfgs', max_iter=1000, class_weight='balanced')\n",
    "logreg_balanced.fit(X_train, y_train)\n",
    "logreg_balanced_preds = logreg_balanced.predict(X_test)\n",
    "logreg_balanced_probs = logreg_balanced.predict_proba(X_test)\n",
    "\n",
    "print(\"Balanced Logistic Regression Performance:\")\n",
    "print(classification_report(y_test, logreg_balanced_preds, zero_division=0))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, logreg_balanced_preds))\n",
    "\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_preds = rf.predict(X_test)\n",
    "rf_probs = rf.predict_proba(X_test)\n",
    "\n",
    "print(\"\\nRandom Forest Performance:\")\n",
    "print(classification_report(y_test, rf_preds))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, rf_preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04e29ee-ba87-4197-9cfe-f31b56b5bc81",
   "metadata": {},
   "source": [
    "### Unbalanced Logistic Regression (Retrospective)\n",
    "\n",
    "While our main model flow uses the balanced logistic regression setup, we also trained an unbalanced logistic regression as a conceptual baseline. This helped us understand how class imbalance affected model predictions, particularly for underrepresented outcomes like draws.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2dc36a-f77e-4ddc-8742-66077a2a647a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unbalanced Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Train logistic regression WITHOUT class balancing\n",
    "logreg = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "logreg_preds = logreg.predict(X_test)\n",
    "logreg_probs = logreg.predict_proba(X_test)\n",
    "\n",
    "print(\"Unbalanced Logistic Regression Performance:\")\n",
    "print(classification_report(y_test, logreg_preds, zero_division=0))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, logreg_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50098e67-27bf-43ba-a692-e2720c835974",
   "metadata": {},
   "source": [
    "### Expected Value (EV) Calculation and Backtest Simulation\n",
    "\n",
    "We calculate the expected value (EV) for each outcome using the model’s predicted probabilities and bookmaker odds. We then simulate placing a $1 bet on each positive EV opportunity to calculate total profit and average ROI. This combined analysis helps assess whether following the model’s recommendations would have been profitable historically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d401127-a4f4-48c8-8df3-a6357f63d377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use balanced model probabilities for backtest\n",
    "probs_balanced = pd.DataFrame(logreg_balanced_probs, columns=['Prob_Home', 'Prob_Draw', 'Prob_Away'], index=X_test.index)\n",
    "X_test_copy = X_test.copy()\n",
    "X_test_copy['True_Result'] = y_test.values\n",
    "X_test_copy['Home_Odds'] = df.loc[X_test_copy.index, 'Home_Odds'].values\n",
    "X_test_copy['Draw_Odds'] = df.loc[X_test_copy.index, 'Draw_Odds'].values\n",
    "X_test_copy['Away_Odds'] = df.loc[X_test_copy.index, 'Away_Odds'].values\n",
    "X_test_copy = pd.concat([X_test_copy, probs_balanced], axis=1)\n",
    "\n",
    "# Calculate EV\n",
    "X_test_copy['EV_Home'] = (X_test_copy['Prob_Home'] * X_test_copy['Home_Odds']) - (1 - X_test_copy['Prob_Home'])\n",
    "X_test_copy['EV_Draw'] = (X_test_copy['Prob_Draw'] * X_test_copy['Draw_Odds']) - (1 - X_test_copy['Prob_Draw'])\n",
    "X_test_copy['EV_Away'] = (X_test_copy['Prob_Away'] * X_test_copy['Away_Odds']) - (1 - X_test_copy['Prob_Away'])\n",
    "X_test_copy['Best_Bet'] = X_test_copy[['EV_Home', 'EV_Draw', 'EV_Away']].idxmax(axis=1)\n",
    "X_test_copy['Best_Bet_EV'] = X_test_copy[['EV_Home', 'EV_Draw', 'EV_Away']].max(axis=1)\n",
    "\n",
    "# Backtest: assume $1 per +EV bet\n",
    "positive_ev_bets = X_test_copy[X_test_copy['Best_Bet_EV'] > 0]\n",
    "def check_win(row):\n",
    "    if row['Best_Bet'] == 'EV_Home' and row['True_Result'] == 0:\n",
    "        return row['Home_Odds'] - 1  # Profit = odds - stake\n",
    "    elif row['Best_Bet'] == 'EV_Draw' and row['True_Result'] == 1:\n",
    "        return row['Draw_Odds'] - 1\n",
    "    elif row['Best_Bet'] == 'EV_Away' and row['True_Result'] == 2:\n",
    "        return row['Away_Odds'] - 1\n",
    "    else:\n",
    "        return -1  # Loss = -1 stake\n",
    "\n",
    "positive_ev_bets['Profit'] = positive_ev_bets.apply(check_win, axis=1)\n",
    "total_profit = positive_ev_bets['Profit'].sum()\n",
    "num_bets = len(positive_ev_bets)\n",
    "roi = total_profit / num_bets if num_bets > 0 else 0\n",
    "\n",
    "print(f\"Backtest Results on {num_bets} +EV Bets:\")\n",
    "print(f\"Total Profit: ${total_profit:.2f}\")\n",
    "print(f\"ROI per bet: {roi:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd18c938-ec05-4657-b0a0-ffb156c02c83",
   "metadata": {},
   "source": [
    "### Results and Discussion\n",
    "\n",
    "We visualize the distribution of positive EV bets, highlight the top five bets, and summarize the average, maximum, and minimum EV across all bets. These insights help us interpret how promising the model's recommendations are and which betting opportunities stand out.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1598efc6-8729-4874-8144-0d5f7d6ec216",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot distribution of best EV\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(positive_ev_bets['Best_Bet_EV'], bins=20, edgecolor='k')\n",
    "plt.title('Distribution of Positive Expected Value (EV) Bets')\n",
    "plt.xlabel('Expected Value')\n",
    "plt.ylabel('Number of Bets')\n",
    "plt.show()\n",
    "\n",
    "# Show top 5 bets by EV\n",
    "top_ev_bets = positive_ev_bets.sort_values('Best_Bet_EV', ascending=False).head()\n",
    "print(\"Top 5 +EV Bets:\")\n",
    "print(top_ev_bets[['Best_Bet', 'Best_Bet_EV', 'Prob_Home', 'Prob_Draw', 'Prob_Away', 'Home_Odds', 'Draw_Odds', 'Away_Odds']])\n",
    "\n",
    "# Summary stats\n",
    "mean_ev = positive_ev_bets['Best_Bet_EV'].mean()\n",
    "max_ev = positive_ev_bets['Best_Bet_EV'].max()\n",
    "min_ev = positive_ev_bets['Best_Bet_EV'].min()\n",
    "\n",
    "print(f\"\\nSummary of Positive EV Bets:\")\n",
    "print(f\"Average EV: {mean_ev:.3f}\")\n",
    "print(f\"Max EV: {max_ev:.3f}\")\n",
    "print(f\"Min EV: {min_ev:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a2f0a2-c92f-4bb1-8081-c8e1a2a1f1a4",
   "metadata": {},
   "source": [
    "### Limitations and Future Work\n",
    "\n",
    "While our project successfully identifies positive expected value (EV) betting opportunities using historical English Premier League data, there are several limitations. \n",
    "\n",
    "First, we rely solely on bookmaker odds and historical match outcomes, without incorporating richer features like recent team form, player injuries, or lineup changes. Our models also assume that past betting market inefficiencies will continue into the future, which may not hold true.\n",
    "\n",
    "Additionally, our sample size is limited to one season, and we only use simple models (logistic regression, random forest). More advanced methods like gradient boosting, ensemble models, or deep learning could potentially improve predictions.\n",
    "\n",
    "In the future, we aim to incorporate live odds data using APIs, expand the feature set with advanced team and player statistics, and perform longer-term backtests across multiple seasons to better assess strategy robustness.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
